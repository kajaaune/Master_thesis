{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from orix import io, plot\n",
    "from hyperspy import signal as signal\n",
    "import numpy as np #General numerical and matrix support\n",
    "from pyxem.utils import indexation_utils as iutls\n",
    "from orix.quaternion import Rotation, symmetry, Orientation\n",
    "from orix.vector.vector3d import Vector3d\n",
    "from orix import plot\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"backend\"] = \"Agg\"\n",
    "from orix.crystal_map.crystal_map import CrystalMap\n",
    "import itertools\n",
    "import dask.array as da\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import crystal maps Crystal maps\n",
    "Not needed for angle cleanup method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import xmaps\n",
    "\n",
    "# xmap1_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_123856_xmap.h5\")\n",
    "# xmap2_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_131643_xmap.h5\")\n",
    "# xmap3_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_135554_xmap.h5\")\n",
    "# xmap4_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_144154_xmap.h5\")\n",
    "# xmap5_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_160122_xmap.h5\")\n",
    "# xmap6_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_164221_xmap.h5\")\n",
    "xmap1_ = io.load(\"D:/Master_thesis/Centered_xmaps/aligned_xmap_1.h5\")\n",
    "xmap2_ = io.load(\"D:/Master_thesis/Centered_xmaps/aligned_xmap_2.h5\")\n",
    "xmap3_ = io.load(\"D:/Master_thesis/Centered_xmaps/aligned_xmap_3.h5\")\n",
    "xmap4_ = io.load(\"D:/Master_thesis/Centered_xmaps/aligned_xmap_4.h5\")\n",
    "xmap5_ = io.load(\"D:/Master_thesis/Centered_xmaps/aligned_xmap_5.h5\")\n",
    "xmap6_ = io.load(\"D:/Master_thesis/Data_from_workstation/180224/20240208_164221_xmap.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting color maps\n",
    "def make_colormap(xmap): # Plotting the orientation map \n",
    "    ipf_key = plot.IPFColorKeyTSL(xmap.phases[0].point_group, direction=Vector3d.zvector())\n",
    "    # ipf_key.plot()\n",
    "    rgb = ipf_key.orientation2color(xmap.orientations)\n",
    "    xmap.plot(rgb, remove_padding=True, return_figure=True,scalebar_properties=dict(location=\"lower left\", frameon=False))\n",
    "    # xmap.plot(rgb, overlay = xmap.correlation[:,0],remove_padding=True, return_figure=True,scalebar_properties=dict(location=\"lower left\", frameon=True))\n",
    "    \n",
    "def make_colormap_error(xmap,error): # Plot orientation map overlaid with the TMA\n",
    "    ipf_key = plot.IPFColorKeyTSL(xmap.phases[0].point_group, direction=Vector3d.zvector())\n",
    "    # ipf_key.plot()\n",
    "    rgb = ipf_key.orientation2color(xmap.orientations)\n",
    "    error_overlay = np.ndarray.flatten(error)\n",
    "    error_overlay = 1-(error_overlay/np.max(error_overlay))\n",
    "    xmap.plot(rgb, overlay=error_overlay, remove_padding=True, return_figure=True,scalebar_properties=dict(location=\"lower left\", frameon=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle cleanup method\n",
    "### Total misorientation angle (TMA):\n",
    "$\\alpha_{TMA} = |m_{12}-\\alpha_{12}|+|m_{13}-\\alpha_{13}|+|m_{23}-\\alpha_{23}|$\n",
    "\n",
    "m is calculated misorientation angle between orientations, $\\alpha$ is actual angle difference between tilts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_slice(dict,start_y,end_y): # Slice the dictionaries\n",
    "    keys = dict.keys()\n",
    "    for i in keys:\n",
    "        dict[f'{i}'] = dict[f'{i}'][start_y:end_y,:]\n",
    "    return dict\n",
    "\n",
    "\n",
    "def combos_func(iterables_array): # Find all combinations of an array\n",
    "    return np.array(list(itertools.product(*iterables_array)))\n",
    "\n",
    "def change_step_size(xmap, pixel_size, scan_unit): # Change the step size of an orix CrystalMap, also update rotations\n",
    "    x = xmap.x * pixel_size\n",
    "    y = xmap.y * pixel_size\n",
    "    rot = xmap.rotations\n",
    "    phaseid = xmap.phase_id\n",
    "    prop = xmap.prop\n",
    "    is_in_data = xmap.is_in_data\n",
    "    phaselist = xmap.phases\n",
    "    new_xmap = CrystalMap(rotations = rot,\n",
    "                        phase_id = phaseid,\n",
    "                        x = x,\n",
    "                        y = y,\n",
    "                        prop = prop,\n",
    "                        scan_unit = scan_unit,\n",
    "                        is_in_data = is_in_data,\n",
    "                        phase_list=phaselist)\n",
    "    return new_xmap\n",
    "\n",
    "\n",
    "def fast_compare(best1,best2,best3,sign1,sign2,sign3,corr1,corr2,corr3,res1,res2,res3,errors,n_best): # Find all combinations, calculate TMA and choose smallest TMA\n",
    "    a,b,c = np.shape(best1)\n",
    "    nr = 5\n",
    "    tilt1,tilt2,tilt3 = np.ones((a,b,c,nr)),np.ones((a,b,c,nr)),np.ones((a,b,c,nr))\n",
    "    numerated = np.linspace(0,c-1,c,dtype='int')\n",
    "\n",
    "\n",
    "    tilt1[:,:,:,0],tilt2[:,:,:,0],tilt3[:,:,:,0] = best1,best2,best3\n",
    "    tilt1[:,:,:,1],tilt2[:,:,:,1],tilt3[:,:,:,1] = sign1,sign2,sign3\n",
    "    tilt1[:,:,:,2],tilt2[:,:,:,2],tilt3[:,:,:,2] = corr1,corr2,corr3\n",
    "    tilt1[:,:,:,3],tilt2[:,:,:,3],tilt3[:,:,:,3] = numerated,numerated,numerated\n",
    "\n",
    "    # make all possible combinations of the three tilts\n",
    "    iterables_array = np.zeros((a,b,3,c,nr))\n",
    "    iterables_array[:,:,0],iterables_array[:,:,1],iterables_array[:,:,2] = tilt1,tilt2,tilt3\n",
    "    combos = np.ones((a,b,c*c*c,3,nr))\n",
    "    for iy,ix in np.ndindex(best1.shape[0:2]):\n",
    "        combos[iy,ix] = combos_func(iterables_array[iy,ix])\n",
    "\n",
    "    # find misorientation angles between all three:\n",
    "    misoris_tot = np.zeros((a,b,c**3))\n",
    "    for iy,ix in np.ndindex(a,b):\n",
    "        ind_res1 = combos[iy,ix,:,0,3].astype(int)\n",
    "        ind_res2 = combos[iy,ix,:,1,3].astype(int)\n",
    "        ind_res3 = combos[iy,ix,:,2,3].astype(int)\n",
    "        os1 = Orientation.from_euler(np.deg2rad(res1['orientation'][iy,ix,ind_res1]),symmetry=symmetry.Oh)#.map_into_symmetry_reduced_zone()\n",
    "        os2 = Orientation.from_euler(np.deg2rad(res2['orientation'][iy,ix,ind_res2]),symmetry=symmetry.Oh)#.map_into_symmetry_reduced_zone()\n",
    "        os3 = Orientation.from_euler(np.deg2rad(res3['orientation'][iy,ix,ind_res3]),symmetry=symmetry.Oh)#.map_into_symmetry_reduced_zone()\n",
    "        \n",
    "        # Calculate the TMA\n",
    "        misoris_tot[iy,ix] = (np.abs(os1.angle_with(os2,degrees = True)-5) +   # tilts 1 to 2\n",
    "                        np.abs(os1.angle_with(os3,degrees = True)-5) + # tilts 1 to \n",
    "                        np.abs(os2.angle_with(os3,degrees = True)-7.07))    # tilts 2 to 3 \n",
    "\n",
    "    min_elems = np.ones((a,b,3,nr))\n",
    "    for iy,ix in np.ndindex(a,b):\n",
    "        ind = np.argmin(misoris_tot[iy,ix])\n",
    "\n",
    "        # if misoris_tot[iy,ix,ind]<0.5: # Could work for not having to update all orientations every time\n",
    "        #     continue\n",
    "        min_elems[iy,ix] = combos[iy,ix,ind]\n",
    "        min_elems[iy,ix,:,-1] = misoris_tot[iy,ix,ind]\n",
    "        comb_2 = min_elems\n",
    "\n",
    "        res1['template_index'][iy,ix,0] = comb_2[iy,ix,0,0].astype(int)\n",
    "        res2['template_index'][iy,ix,0] = comb_2[iy,ix,1,0].astype(int)\n",
    "        res3['template_index'][iy,ix,0] = comb_2[iy,ix,2,0].astype(int)\n",
    "\n",
    "        res1['mirrored_template'][iy,ix,0] = comb_2[iy,ix,0,1].astype(int)\n",
    "        res2['mirrored_template'][iy,ix,0] = comb_2[iy,ix,1,1].astype(int)\n",
    "        res3['mirrored_template'][iy,ix,0] = comb_2[iy,ix,2,1].astype(int)\n",
    "\n",
    "        ind_res1 = comb_2[iy,ix,0,3].astype(int)\n",
    "        ind_res2 = comb_2[iy,ix,1,3].astype(int)\n",
    "        ind_res3 = comb_2[iy,ix,2,3].astype(int)\n",
    "\n",
    "        res1['orientation'][iy,ix,0] = res1['orientation'][iy,ix,ind_res1]\n",
    "        res2['orientation'][iy,ix,0] = res2['orientation'][iy,ix,ind_res2]\n",
    "        res3['orientation'][iy,ix,0] = res3['orientation'][iy,ix,ind_res3]\n",
    "\n",
    "        res1['correlation'][iy,ix,0] = comb_2[iy,ix,0,2].astype(int)\n",
    "        res2['correlation'][iy,ix,0] = comb_2[iy,ix,1,2].astype(int)\n",
    "        res3['correlation'][iy,ix,0] = comb_2[iy,ix,2,2].astype(int)\n",
    "\n",
    "        errors[iy,ix] = comb_2[iy,ix,0,-1]\n",
    "        n_best[iy,ix,0] = ind_res1\n",
    "        n_best[iy,ix,1] = ind_res2\n",
    "        n_best[iy,ix,2] = ind_res3\n",
    "\n",
    "\n",
    "def cleanup_for_part(res1,res2,res3,errors,n_best,start_y,end_y): # Takes parts of the dataset and calls fast_compare()\n",
    "    res1,res2,res3 = dict_slice(res1.copy(),start_y,end_y),dict_slice(res2.copy(),start_y,end_y),dict_slice(res3.copy(),start_y,end_y)\n",
    "\n",
    "    d_best1, d_best2, d_best3 = res1['template_index'], res2['template_index'], res3['template_index']\n",
    "    d_sign1, d_sign2, d_sign3  = res1['mirrored_template'], res2['mirrored_template'], res3['mirrored_template']\n",
    "    d_corr1, d_corr2, d_corr3 = res1['correlation'], res2['correlation'], res3['correlation']    \n",
    "    d_sign1 = d_sign1.astype(int)\n",
    "    d_sign1[d_sign1==0] = -1\n",
    "    d_sign2 = d_sign2.astype(int)\n",
    "    d_sign2[d_sign2==0] = -1\n",
    "    d_sign3 = d_sign3.astype(int)\n",
    "    d_sign3[d_sign3==0] = -1\n",
    "    a,b,c = np.shape(d_best1)[0:3]\n",
    "\n",
    "    c_size = 5 # Chunk size\n",
    "\n",
    "    dask_array_return = da.map_blocks(func=fast_compare,best1=d_best1,best2=d_best2,best3=d_best3,\n",
    "                                      sign1=d_sign1,sign2=d_sign2,sign3=d_sign3,\n",
    "                                      corr1=d_corr1,corr2=d_corr2,corr3=d_corr3,\n",
    "                                      res1=res1,res2=res2,res3=res3,errors=errors,n_best=n_best, dtype=object,chunks=(c_size,c_size,c))\n",
    "\n",
    "    dask_array_return.compute()\n",
    "\n",
    "    \n",
    "            \n",
    "def cleanup(res1,res2,res3,phase): # Main function for the ACM. Call to run the ACM. Returns the updated Crystal maps, the error_array (TMA), and the n_best_array\n",
    "    start_time = time.process_time()\n",
    "    cs = symmetry.Oh\n",
    "\n",
    "    y,x = np.shape(res1['template_index'])[0:2]\n",
    "    errors = np.zeros((y,x))\n",
    "    n_best = np.zeros((y,x,3))\n",
    "\n",
    "    # Nan to Num\n",
    "    res1['correlation'][:,:] = np.nan_to_num(res1['correlation'][:,:])\n",
    "    res2['correlation'][:,:] = np.nan_to_num(res2['correlation'][:,:])\n",
    "    res3['correlation'][:,:] = np.nan_to_num(res3['correlation'][:,:])\n",
    "\n",
    "    divide_lim = 2 # pixels\n",
    "    for i in range(divide_lim,y+divide_lim,divide_lim):\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "        if i>y:\n",
    "            cleanup_for_part(res1,res2,res3,errors[i-divide_lim:y,:],n_best[i-divide_lim:y,:],i-divide_lim,y)\n",
    "        else:\n",
    "            cleanup_for_part(res1,res2,res3,errors[i-divide_lim:i,:],n_best[i-divide_lim:i,:],i-divide_lim,i)\n",
    "            \n",
    "    print('Creating xmap')\n",
    "    # Make xmap:\n",
    "    xmap1 = iutls.results_dict_to_crystal_map(res1, phase, diffraction_library=library)\n",
    "    xmap1.phases[0].space_group = 227 \n",
    "    xmap1.correlation = np.nan_to_num(xmap1.correlation) # If any correlation scores are NaN\n",
    "    xmap1 = change_step_size(xmap1,15.356,'nm')\n",
    "\n",
    "    xmap2 = iutls.results_dict_to_crystal_map(res2, phase, diffraction_library=library)\n",
    "    xmap2.phases[0].space_group = 227 \n",
    "    xmap2.correlation = np.nan_to_num(xmap2.correlation) # If any correlation scores are NaN\n",
    "    xmap2 = change_step_size(xmap2,15.356,'nm')\n",
    "\n",
    "    xmap3 = iutls.results_dict_to_crystal_map(res3, phase, diffraction_library=library)\n",
    "    xmap3.phases[0].space_group = 227 \n",
    "    xmap3.correlation = np.nan_to_num(xmap3.correlation) # If any correlation scores are nan\n",
    "    xmap3 = change_step_size(xmap3,15.356,'nm')\n",
    "    end_time = time.process_time()\n",
    "    print(f'Elapsed time: {end_time-start_time}s')\n",
    "\n",
    "    return xmap1, xmap2, xmap3, errors, n_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and aligning data\n",
    "The input datasets must be on dictionary form to be able to change the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "libpath = Path(\"./Libraries/lib_035res.pkl\")\n",
    "with open(libpath, 'rb') as fp: # With b sub\n",
    "    library = pickle.load(fp)\n",
    "\n",
    "resultpath1 = Path(\"D:/Master_thesis/Data_from_workstation/180224/20240208_123856_xmap_result.pkl\")\n",
    "with open(resultpath1, 'rb') as fp: # With b sub\n",
    "    result1 = pickle.load(fp)\n",
    "\n",
    "resultpath2 = Path(\"D:/Master_thesis/Data_from_workstation/180224/20240208_131643_xmap_result.pkl\")\n",
    "with open(resultpath2, 'rb') as fp: # With b sub\n",
    "    result2 = pickle.load(fp)\n",
    "\n",
    "resultpath3 = Path(\"D:/Master_thesis/Data_from_workstation/180224/20240208_160122_xmap_result.pkl\")\n",
    "with open(resultpath3, 'rb') as fp: # With b sub\n",
    "    result3 = pickle.load(fp)\n",
    "\n",
    "\n",
    "phasepath1 = Path(\"D:/Master_thesis/Data_from_workstation/180224/20240208_123856_xmap_phasedict.pkl\")\n",
    "with open(phasepath1, 'rb') as fp: # With b sub\n",
    "    phasedict1 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 275, 30) (520, 275, 30) (520, 275, 30)\n",
      "(20, 20, 23) (20, 20, 23) (20, 20, 23)\n"
     ]
    }
   ],
   "source": [
    "# Choose the size of the dataset to process, and the number of best templates to use\n",
    "keys = result1.keys()\n",
    "for i in keys:\n",
    "    result1[f'{i}'] = result1[f'{i}'][35:-5,5:]\n",
    "    result2[f'{i}'] = result2[f'{i}'][29:-11,5:]\n",
    "    result3[f'{i}'] = result3[f'{i}'][:,:-5]\n",
    "print(np.shape(result1['template_index']),np.shape(result2['template_index']),np.shape(result3['template_index']))\n",
    "\n",
    "limit = 23\n",
    "x1,x2,y1,y2 = 240,260,380,400\n",
    "# x1,x2,y1,y2 = 0,-1,0,-1\n",
    "\n",
    "for i in keys:\n",
    "    result1[f'{i}'] = result1[f'{i}'][y1:y2,x1:x2,0:limit]\n",
    "    result2[f'{i}'] = result2[f'{i}'][y1:y2,x1:x2,0:limit]\n",
    "    result3[f'{i}'] = result3[f'{i}'][y1:y2,x1:x2,0:limit]\n",
    "print(np.shape(result1['template_index']),np.shape(result2['template_index']),np.shape(result3['template_index']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "Creating xmap\n",
      "Elapsed time: 17.328125s\n"
     ]
    }
   ],
   "source": [
    "xmap1,xmap2,xmap3,error_array,n_best_array = cleanup(result1,result2,result3,phasedict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_colormap(xmap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can find the best template indexes for the tilts.\n",
    "xt,yt = 10,10\n",
    "print(f\"n best tilt 1: {np.where(result1['template_index'][xt,yt]==result1['template_index'][xt,yt][0])[0]}\")\n",
    "print(f\"n best tilt 2: {np.where(result2['template_index'][xt,yt]==result2['template_index'][xt,yt][0])[0]}\")\n",
    "print(f\"n best tilt 3: {np.where(result3['template_index'][xt,yt]==result3['template_index'][xt,yt][0])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving cleaned up Crystal maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'grain_boundary'\n",
    "\n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps/{name}_1.h5\", xmap1) \n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps/{name}_2.h5\", xmap2) \n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps/{name}_3.h5\", xmap3) \n",
    "\n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps_ang/{name}_1.ang\", xmap1) \n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps_ang/{name}_2.ang\", xmap2) \n",
    "io.save(f\"D:/Master_thesis/Cleanup_xmaps_ang/{name}_3.ang\", xmap3) \n",
    "\n",
    "with open(f\"D:/Master_thesis/Cleanup_xmaps/error_{name}.pkl\", 'wb') as fp:\n",
    "    pickle.dump(error_array, fp)\n",
    "\n",
    "with open(f\"D:/Master_thesis/Cleanup_xmaps/n_best_{name}.pkl\", 'wb') as fp:\n",
    "    pickle.dump(n_best_array, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
